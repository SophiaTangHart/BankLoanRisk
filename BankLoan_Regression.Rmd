---
title: "<center>Implementing Regression Algorithms</center>"
subtitle: "<center>Using Bank Loan dataset</center>"
date: "<center>`r format(Sys.time(), '%B %Y')`</center>"
author: "<center>Sophia Tang Hart</center>"
output: #html_notebook
  html_document:
      theme: journal
      toc: yes
      toc_depth: 4
      #toc_float: true
  word_document:
      toc: yes
      toc_depth: 4
      #toc_float: true
  pdf_document:
      toc: yes
      theme: journal
      toc_depth: 4
      #toc_float: true
---


# OBJECTIVE AND DATA DESCRIPTION
**Background: **

Banks loan out money to customers to finance a car, a house, pay for education, consolidate loans, etc. Borrowers agree to pay back the money with an interest on a monthly basis. Sometimes, due to unexpected circumstances, some borrowers are not able to pay back the money. 


**Research Objectives: **

For the banks, it would be helpful to see what is the pattern in the customers to predict if a customer can pay back the loan, so the back knows who to lend out the money. I want to predict if any customer goes to a bank, should the bank loan out the money to the customer base on model learned from this dataset. 


**Research Questions: ** 

1. What factors contribute/correlated most to bank loan status?

2. Can we predict if a borrower will be able to pay the debt in full?

3. What Machine Learning algorithms perform best in the prediction? (First Guess)

4. Optimize all (or the best) algorithms. With the fine tuned hyperparameters, what is the best prediction performance? Which algorithm?


**Dataset**

The dataset is taken from Kaggle (https://www.kaggle.com/zaurbegiev/my-dataset). There are over 100,000 rows and 19 columns (features) in this dataset. The predicted feature variable is Loan_Status, which is a categorical variable with value either "Fully Paid" or "Charged off". Fully Paid means the borrower can pay back the debt, while charged off means the borrower is unlikely pay the bank after a substantial delinquent for a period of time. The remainder of the debt is sometimes collected by a third-party agency.
 

LoanID,

CustomerID,

Loan_Status,

Current_Loan_Amount,

Term,

Credit_Score,

Annual_Income,

Years_in_current_job,

Home_Ownership,

Purpose,

Monthly_Debt,

Years_of_Credit_History,

Months_since_last_delinquent,

Number_of_Open_Accounts,

Number_of_Credit_Problems,

Current_Credit_Balance,

Maximum_Open_Credit,

Bankruptcies,

Tax_Liens


# STEP 1: LOADING LIBRARIES AND DATA
```{r message=FALSE, warning=FALSE}
library(caret)
library(dplyr)
library(tidyverse)
library(mlbench)
library(gmodels)
# for multiple plots in one figure (ggarrange)
library(ggpubr)

library(broom)
theme_set(theme_classic())

library(ISLR)
library(pROC)
library(lattice)
library(ggplot2)
library(e1071) 
library(corrplot)
#library(kknn)
#library(multiROC)
library(MLeval)
library(AppliedPredictiveModeling)
library(Hmisc)
#library( ggfortify)
library(splines)
library(mgcv)
library(leaps)
library(MASS)
library(glmnet)

```

## Examing data
```{r message=FALSE, warning=FALSE}

# Clear memory
rm(list=ls())

# read in data
BankLoan_dataset <- read.csv("LoanStatus.csv")

# remove unrelevant fields
BankLoan_dataset <- subset(BankLoan_dataset, select=-c(LoanID, CustomerID))

# data structure
str(BankLoan_dataset)

# data summary
knitr::kable(head(BankLoan_dataset))
knitr::kable(summary(BankLoan_dataset))
```

# STEP 2: DATA PREPROCESSING

## a) Convert to numeric values
```{r message=FALSE, warning=FALSE}

BankLoan_dataset$Years_in_current_job = extract_numeric(BankLoan_dataset$Years_in_current_job)
BankLoan_dataset$Years_in_current_job <- as.numeric(BankLoan_dataset$Years_in_current_job)

```


## b) Convert Categorical Variables
## c) Remove Outliers 
## d) Remove Null

```{r message=FALSE, warning=FALSE}

# # identify outliers
# outliers <- boxplot(BankLoan_dataset$Annual_Income, plot=FALSE)$out
# # remove outliers
# BankLoan_dataset <- BankLoan_dataset[-which(BankLoan_dataset$Annual_Income %in% outliers), ] 
#
```
We cannot remove outliers for individual feature one at a time, because after removing the outliers, some of the records are removing. The rows will be mismatched when we combine the features together. Therefore, we have to use the pipe function like below.

```{r message=FALSE, warning=FALSE}
# show outliers before removing them
histogram(BankLoan_dataset$Annual_Income)

bankloan <- BankLoan_dataset %>%
  # convert string feature into categorical factors
  mutate_if(is.character, as.factor) %>% 
  
  # remove the nulls
  drop_na() %>%

  ### Remove outliers
  # Annual_Income
  filter(between(Annual_Income, 
                 quantile(Annual_Income, 0.25) - 1.5* IQR(Annual_Income),
                 quantile(Annual_Income, 0.75) + 1.5* IQR(Annual_Income))) %>%
  # Current_Loan_Amount
  filter(between(Current_Loan_Amount, 
                 quantile(Current_Loan_Amount, 0.25) - 1.5* IQR(Current_Loan_Amount),
                 quantile(Current_Loan_Amount, 0.75) + 1.5* IQR(Current_Loan_Amount))) %>%
  # Credit_Score
  filter(between(Credit_Score, 
                 quantile(Credit_Score, 0.25) - 1.5* IQR(Credit_Score),
                 quantile(Credit_Score, 0.75) + 1.5* IQR(Credit_Score))) %>%
  #Number_of_Credit_Problems (there is an outlier of 15)
  filter(between(Number_of_Credit_Problems, 
                 quantile(Number_of_Credit_Problems, 0.25) - 1.5* IQR(Number_of_Credit_Problems),
                 4)) %>%
  # Monthly_Debt
  filter(between(Monthly_Debt, 
               quantile(Monthly_Debt, 0.25) - 1.5* IQR(Monthly_Debt),
               quantile(Monthly_Debt, 0.75) + 1.5* IQR(Monthly_Debt))) %>%

  # Maximum_Open_Credit
  filter(between(Maximum_Open_Credit, 
               quantile(Maximum_Open_Credit, 0.25) - 1.5* IQR(Maximum_Open_Credit),
               quantile(Maximum_Open_Credit, 0.75) + 1.5* IQR(Maximum_Open_Credit))) %>%
    
  #remove null after filling outliers with NA
  drop_na()

str(bankloan)
summary(bankloan)

#check if there is null
is.null(bankloan)

# showing no outliers
histogram(bankloan$Annual_Income)

```

Histogram shows outliers are removed. Annual income is skewed right. After removing outliers and Null values, there are still 26,500 data left to work with.


# STEP 3: STATISTICAL SUMMARY

## a) Graphical Summary
```{r message=FALSE, warning=FALSE}
# BAR graph for categorical variables

ggplot(bankloan, aes(x=Purpose)) +
  geom_bar() +
  coord_flip()

gg_status <- ggplot(bankloan, aes(x=Loan_Status)) +
  geom_bar()

gg_home <- ggplot(bankloan, aes(x=Home_Ownership)) +
  geom_bar() +
  coord_flip()

gg_problem <- ggplot(bankloan, aes(x=Number_of_Credit_Problems)) +
  geom_bar() 

gg_job <- ggplot(bankloan, aes(x=Years_in_current_job)) +
  geom_bar() 

# arrange multiple plots in one figure  
figure <- ggarrange(gg_status, gg_home, gg_problem, gg_job,
                    ncol = 2, nrow = 2,
                    legend="none")
figure


# Boxplot for quantitative variables
ggplot(bankloan, aes(x=Loan_Status, y=Annual_Income)) +
  geom_boxplot()

ggplot(bankloan, aes(x=Loan_Status, y=Current_Loan_Amount)) +
  geom_boxplot()

ggplot(bankloan, aes(x=Loan_Status, y=Credit_Score)) +
  geom_boxplot()

ggplot(bankloan, aes(x=Loan_Status, y=Monthly_Debt)) +
  geom_boxplot()

```
From the bar graphs, we can see that the data is imbalanced, Paid Fully is much more than Charge Off. The home_ownership is have_mortgage most and rent is secondly. Most people have zero number of credit problems. Most people work 10+ years in current job. The most purpose of loans is Debt Consolidation.

From the Boxplots, comparing annual income, current loan amount, monthly debt and credit score, annual income seems to be the biggest difference between Fully Paid and Charged Off customers.


## b) Numerical Summary
```{r message=FALSE, warning=FALSE}
# proportion of Paid-fully and Charged-off
table(bankloan$Loan_Status)
round(prop.table(table(bankloan$Loan_Status)) * 100, 1)

# Average group by loan status
# Annual_Income is column5, credit score is column4
aggregate(bankloan[, 4:5], list(bankloan$Loan_Status), median)

```

Numerical statistics shows Fully Paid is 81.8% of the total data. The median annual income for fully paid customers is 1.23M and 1.12M for charged off customers. Since the annual income is right-skew, median is used instead of mean.


# STEP 4: INITIAL EXPLORATION OF LINEAR REGRESSION MODEL

## a) Balancing Data by Downsampling
```{r message=FALSE, warning=FALSE}
set.seed(9650)
# Divide data into train and test sets
indexTrain <- createDataPartition(y=bankloan$Loan_Status, p=0.75, list=FALSE) 
training <- bankloan[indexTrain, ]
testing <- bankloan[-indexTrain, ]

# Since there are 26000 of data, take a subset of data for visual clarity
training <- training[1:2000, ]
testing <- testing[1:500, ]

# Downsampling to balance data
sub_down_train <- downSample(x=training[, -ncol(training)], y=training$Loan_Status)
down_test <- downSample(x=testing[, -ncol(testing)], y=testing$Loan_Status)

table(sub_down_train$Loan_Status)
table(down_test$Loan_Status)
```
Data are balanced with downsampling. 

## b) Credit Score vs. Income

```{r message=FALSE, warning=FALSE}
# Credit Score as a function of Income
reg_model <- lm(Credit_Score ~ Annual_Income, data=sub_down_train)
# Linear regression model summary
reg_model

# Create diagnostic plots
reg_model.diagnostic <- augment(reg_model)
knitr::kable(head(reg_model.diagnostic))

# Scatter plot and best fitted line
ggplot(reg_model.diagnostic, aes(Annual_Income, Credit_Score)) +
  geom_point() +
  # linear model, don't show standard error
  stat_smooth(method=lm, se=FALSE) + 
  #fitted shows the residual error
  geom_segment(aes(xend=Annual_Income, yend=.fitted), color='red', size=0.3) 

# Diagnostic plots
par(mfrow = c(2,2))
plot(reg_model)

# The diagnostic plots show residuals in four different ways:
# 
# Residuals vs Fitted: This diagnostic plot is an indicator of the Linearity or Non Linearity of the relationship.If there is no perceivable pattern around the central horizontal curve then the relationship is linear.
# 
# Normal Q-Q: This diagnostic plot ascertains whether the residuals are normally distributed.If the resiuals are algned to the central diagonal then the residuals follow a straight line.
# 
# Scale-Location: This diagnostic is to evaluate the homogeneity of variance of the residuals .If the residuals are spread uniformly around the central line then the residuals are homoscedastic.
# 
# Residuals vs Leverage. Used to identify influential cases, that is extreme values that might influence the regression results when included or excluded from the analysis.  

# Cook's distance is used to evaluate the Influential points that will alter the Regression analysis or the coefficients values.
```
The scatter plot does not show much pattern in Credit Score vs. Annual Income. In the diagnostic plots: 1. It does not show very good linearity, there are more negative residual error than positive residual error. 2. Normality is not completely, because the two ends of the curve are not on the diagonal. 3. Constant Variance is true, because there is no apparent pattern on the residual error, homoscedastic is checked. 4. There are a few influential cases.

## c) IMPROVEMENT
### Current_Credit_Balance vs. Maximum_Open_Credit
                        
```{r message=FALSE, warning=FALSE}
set.seed(9650)

# Credit Score as a function of Income
#reg_model <- lm(Credit_Score ~ Annual_Income, data=sub_down_train)
reg_model <- lm(Current_Credit_Balance ~ Maximum_Open_Credit, data=sub_down_train)
# Linear regression model summary
reg_model

# Create diagnostic plots
reg_model.diagnostic <- augment(reg_model)

knitr::kable(head(reg_model.diagnostic))

# Scatter plot and best fitted line
#ggplot(reg_model.diagnostic, aes(Annual_Income, Credit_Score)) +
ggplot(reg_model.diagnostic, aes(Maximum_Open_Credit, Current_Credit_Balance)) +
  geom_point() +
  # linear model, don't show standard error
  stat_smooth(method=lm, se=FALSE) + 
  #fitted shows the residual error
  geom_segment(aes(xend=Maximum_Open_Credit, yend=.fitted), color='red', size=0.3) 

# Diagnostic plots
par(mfrow = c(2,2))
plot(reg_model)
plot(reg_model, 4)
knitr::kable(head(sub_down_train), format='html')

# The diagnostic plots show residuals in four different ways:
# 
# Residuals vs Fitted: This diagnostic plot is an indicator of the Linearity or Non Linearity of the relationship.If there is no perceivable pattern around the central horizontal curve then the relationship is linear.
# 
# Normal Q-Q: This diagnostic plot ascertains whether the residuals are normally distributed.If the resiuals are algned to the central diagonal then the residuals follow a straight line.
# 
# Scale-Location: This diagnostic is to evaluate the homogeneity of variance of the residuals .If the residuals are spread uniformly around the central line then the residuals are homoscedastic.
# 
# Residuals vs Leverage. Used to identify influential cases, that is extreme values that might influence the regression results when included or excluded from the analysis.  

# Cook's distance is used to evaluate the Influential points that will alter the Regression analysis or the coefficients values.

```
The scatter plot shows there is a pattern and can be modeled using simple linear regression. In the diagnostic plots: 1. It is linear, there are equally negative residual error and positive residual error. 2. Normality is true within -2 to 2 quantile. They are no the diagonal, but the two ends of the curve are not on the diagonal. 3. Constant Variance is true, because there is no apparent pattern on the residual error, homoscedastic is checked. 4. There are a few influential cases: record 10, 578 and 713. So I'll remove them on the models below.

# STEP 5: EXAMING FEATURES

## a) Feature Visualization
```{r message=FALSE, warning=FALSE}

transparentTheme(trans=.4)
#theme(plot.title = element_text(size = .1))

ggplot(sub_down_train, aes(x=Credit_Score)) +
  geom_histogram(aes(y=..density..), # histogram with density instead of count on y-axis
                 binwidth = 0.5,
                 colour='black', fill='white') +
  geom_density(alpha=0.2, fill='#FF6666')

ggplot(sub_down_train, aes(x=Annual_Income)) +
  geom_histogram(aes(y=..density..), # histogram with density instead of count on y-axis
                 binwidth = 0.5,
                 colour='black', fill='white') +
  geom_density(alpha=0.2, fill='#FF6666')

# Try different methods to transform into normal distribution
hist(log2(sub_down_train$Annual_Income))
hist((sub_down_train$Annual_Income)^2)
hist(sqrt(sub_down_train$Annual_Income))

# feature plots
# Taking only quantitative variables
featurePlot(x=sub_down_train[c(2,4,5,6,9,10,11,12,14,15)],
            y=sub_down_train$Loan_Status,
            plot='density',
            scales = list(x=list(relation='free'),
                          y=list(relation='free')),
            adjust=1.5,
            pch='|',
            layout = c(5,2),
             #number.cex = 0.05,
            auto.key=list(columns=5))

# write a function to make boxplot of a list of variables
customPlot <- function(varName) {
  sub_down_train %>%
    group_by_('Loan_Status') %>%
    select_('Loan_Status', varName) %>%
    ggplot(aes_string('Loan_Status', varName, fill='Loan_Status')) +
    geom_boxplot() +
    scale_fill_manual(values=c('#999999', '#E69F00')) +
    facet_wrap(~Loan_Status)
}

varlist <- c('Annual_Income', 'Credit_Score', 'Maximum_Open_Credit', 'Years_in_current_job', 'Current_Credit_Balance')
lapply(varlist, customPlot)
```
Credit score is left-skew and Annual Income is right skewed. Using log2 and square do not transform Annual Income to normal distribution, but square root does transform it to normal. 

Features plots show all the quantitative features and comparing base on Loan Status. The features plots give us better picture on what are the features that are very different between the two Loan Status (Fully Paid and Charged Off). For these very different features, boxplots are plotted for more detail visualization. Some of the boxplots were compared in Graphical Statisically Summary above but less systematic way. We see that Annual Income and Years in Current Jobs are most different between the two classes. 

## b) Feature Correlation
```{r warning=FALSE, message=FALSE}

# remove categorical variables, since correlation is for quantitative variables
correlation_r <- rcorr(as.matrix(sub_down_train[c(-1,-3,-7,-8,-13,-16,-17)]))

correlation_matrix <- correlation_r$r

# p-value
p_mat <- correlation_r$P 
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))

# only plot variables with significant level above 0.05 (95% confidence)
corsig <- corrplot(correlation_matrix, method='color', col=col(200),
                   type='upper', order='hclust', 
                   addCoef.col = 'black', # add coefficient of correlation
                   tl.col='darkblue', tl.srt = 45, # text label color and rotation
                   p.mat=p_mat, sig.level=0.05, insig='blank',
                   diag = FALSE,
                   title = 'Correlation Between Significant Variables',
                   mar=c(0,0,1,0),
                   number.cex = 0.5 # font for correlation coefficients
                   )

```
Feature correlation plot shows the features that are 95% confident that they are correlated. Current Credit Balance and Maximum Open Credit have strong correlation with r=0.76. This means the more money someone is allowed to borrow, the more they would borrow. Or the more someone borrows, the more they are allowed to borrow. Annual Income and Monthly Debt are moderately correlated with r=0.53. This means the more income one has, the more expenditure he/she will have and the more debt he/shw has. 


# STEP 6: CLOSER LOOK OF LINEAR REGRESSION MODELS 

## a) Current_Credit_Balance vs. Maximum_Open_Credit
```{r message=FALSE, warning=FALSE}
set.seed(9650)

# Remove influential cases
bankloan <-bankloan[c(-10, -578, -713), ]
  
# Set up train and test set
indexTrain <- createDataPartition(y=bankloan$Loan_Status, p=0.75, list=FALSE) 
training <- bankloan[indexTrain, ]
testing <- bankloan[-indexTrain, ]

# Since there are 26000 of data, take a subset of data for visual clarity
training <- training[1:2000, ]
testing <- testing[1:500, ]

# Downsampling to balance data
sub_train <- downSample(x=training[, -ncol(training)], y=training$Loan_Status)
sub_test <- downSample(x=testing[, -ncol(testing)], y=testing$Loan_Status)

table(sub_train$Loan_Status)
table(sub_test$Loan_Status)

# Set up cross validation and control parameters 
control <- trainControl(method='repeatedcv', number=10, repeats=1, verbose=FALSE, search='grid')
metric <- 'RMSE'
tunelength <- 10

# Train linear regression model
# fit_LR <- caret::train() if can't recognize the caret package
fit_LR <- train(Current_Credit_Balance ~ Maximum_Open_Credit, data=sub_train, method='lm', metric=metric, preProc=c('center', 'scale', 'BoxCox'), trControl=control, tunelength=tunelength, verbose=FALSE)
summary(fit_LR)

# Prediction
predictions <- predict(fit_LR, newdata=sub_test)

# Evaluation
rmse <- RMSE(predictions, sub_test$Current_Credit_Balance)
rmse

# Error rate
error_rate <- rmse/mean(sub_test$Current_Credit_Balance)
error_rate
```
p-value is less than 2e-16. So the Current Open Credit and Maximum Open Credit relationship is significant. The intercept a=201592 and slope b=110471. 56% of the variation in Current Open Credit can be modeled by this linear relationship, and the rest 44% is due to other factors. This relationship means the more money someone is allowed to borrow, the more they would borrow. Error rate is 47%. This is moderately high considered all the outliers have been removed as well as the influential cases.

## b) Current Credit Balance vs. Annual Income
```{r message=FALSE, warning=FALSE}

# Set up cross validation and control parameters 
control <- trainControl(method='repeatedcv', number=10, repeats=1, verbose=FALSE, search='grid')
metric <- 'RMSE'
tunelength <- 10

# Train linear regression model
# fit_LR <- caret::train() if can't recognize the caret package
fit_LR <- train(Current_Credit_Balance ~ Annual_Income, data=sub_train, method='lm', metric=metric, preProc=c('center', 'scale', 'BoxCox'), trControl=control, tunelength=tunelength, verbose=FALSE)
summary(fit_LR)

# Prediction
predictions <- predict(fit_LR, newdata=sub_test)

# Evaluation
rmse <- RMSE(predictions, sub_test$Current_Credit_Balance)
rmse

# Error rate
error_rate <- rmse/mean(sub_test$Current_Credit_Balance)
error_rate

```
The relationship between Current Credit Balance and Annual Income is also significant, since p-value=3.57e-15. The intercept a=201592. This is the same as previous model relationship. This makes sense because in the absence of Annual Income or Maximum Open Balance, a=201592. The slope b=41397. 7.8% of the variation in Current Open Credit can be modeled by this linear relationship, and the rest 98.2% is due to other factors. Error rate is 69%. This is high considered all the outliers have been removed as well as the influential cases.

## c) Monthly Debt vs. Annual Income
```{r message=FALSE, warning=FALSE}

# Set up cross validation and control parameters 
control <- trainControl(method='repeatedcv', number=10, repeats=1, verbose=FALSE, search='grid')
metric <- 'RMSE'
tunelength <- 10

# Train linear regression model
# fit_LR <- caret::train() if can't recognize the caret package
fit_LR <- train(Monthly_Debt ~ Annual_Income, data=sub_train, method='lm', metric=metric, preProc=c('center', 'scale', 'BoxCox'), trControl=control, tunelength=tunelength, verbose=FALSE)
summary(fit_LR)

# Prediction
predictions <- predict(fit_LR, newdata=sub_test)

# Evaluation
rmse <- RMSE(predictions, sub_test$Monthly_Debt)
rmse

# Error rate
error_rate <- rmse/mean(sub_test$Monthly_Debt)
error_rate

```
The relationship between Monthly Debt and Annual Income is also significant, since p-value=2e-16. The intercept a=16725.9. The slope b=5021.6. 30% of the variation in Monthly Debt can be modeled by this linear relationship, and the rest 70% is due to other factors. Error rate is 40%. This is moderately high considered all the outliers have been removed as well as the influential cases.

## d) Monthly Debt vs Annual_Income*Maximum_Open_Credit

```{r message=FALSE, warning=FALSE}

# Set up cross validation and control parameters 
control <- trainControl(method='repeatedcv', number=10, repeats=1, verbose=FALSE, search='grid')
metric <- 'RMSE'
tunelength <- 10

# Train linear regression model
# fit_LR <- caret::train() if can't recognize the caret package
fit_LR <- train(Monthly_Debt ~ Annual_Income*Maximum_Open_Credit, data=sub_train, method='lm', metric=metric, preProc=c('center', 'scale', 'BoxCox'), trControl=control, tunelength=tunelength, verbose=FALSE)
summary(fit_LR)

# Prediction
predictions <- predict(fit_LR, newdata=sub_test)

# Evaluation
rmse <- RMSE(predictions, sub_test$Monthly_Debt)
rmse

# Error rate
error_rate <- rmse/mean(sub_test$Monthly_Debt)
error_rate

```
The relationship between Monthly Debt and the combined effects of Annual Income and Maximum Open Credit is also not significant, since p-value=0.96. This could be misleading because of multicollinearity between variables. The relationship is significant for each variable individually. The intercept a=16725.9. 33% of the variation in Monthly Debt can be modeled by this linear relationship, and the rest 67% is due to other factors. Error rate is 39%. This is moderately high considered all the outliers have been removed as well as the influential cases.

## e) Monthly Debt vs. Purpose

```{r message=FALSE, warning=FALSE}

#sub_train$Purpose <- as.character(sub_train$Purpose)
#sub_test$Purpose <- as.character(sub_test$Purpose)
sub_train$Purpose <- as.factor(sub_train$Purpose)
sub_test$Purpose <- as.factor(sub_test$Purpose)


# Set up cross validation and control parameters 
control <- trainControl(method='repeatedcv', number=10, repeats=1, verbose=FALSE, search='grid')
metric <- 'RMSE'
tunelength <- 10

# Train linear regression model
# fit_LR <- caret::train() if can't recognize the caret package
fit_LR <- train(Monthly_Debt ~ Purpose, data=sub_train, method='lm', metric=metric, preProc=c('center', 'scale', 'BoxCox'), trControl=control, tunelength=tunelength, verbose=FALSE)
summary(fit_LR)

```
Purpose is a categorical variable. I am not sure how to interpredit when there is a p-value depending on the value of Purpose. But the combined p-value is 0.0035, so the relationship is significant and 2.3% of variation is due to this relationship.

## f) Monthly_Debt vs. Annual_Income+Current_Credit_Balance+Maximum_Open_Credit+Annual_Income*Maximum_Open_Credit

```{r message=FALSE, warning=FALSE}

# Set up cross validation and control parameters 
control <- trainControl(method='repeatedcv', number=10, repeats=1, verbose=FALSE, search='grid')
metric <- 'RMSE'
tunelength <- 10

# Train linear regression model
# fit_LR <- caret::train() if can't recognize the caret package
fit_LR <- train(Monthly_Debt ~ Annual_Income+Current_Credit_Balance+Maximum_Open_Credit+Annual_Income*Maximum_Open_Credit, data=sub_train, method='lm', metric=metric, preProc=c('center', 'scale', 'BoxCox'), trControl=control, tunelength=tunelength, verbose=FALSE)
summary(fit_LR)

```
The relationship of Monthly Debt is significant with Annual Income and with Current Credit Balance (just like predicted earlier). But the relationship is not significant with Maximum Open Credit or the combined effect of Annual Income and Maximum Open Credit. Again, this could be misleading because of multicollinearity between variables. 


# STEP 7: NONLINEAR REGRESSION

## a) Polynomial
```{r message=FALSE, warning=FALSE}

set.seed(9650)

# 
poly_reg <- lm(Monthly_Debt ~ poly(Annual_Income, 2), data=sub_train)
predictions <- poly_reg %>% predict(sub_test)

rmse <- RMSE(predictions, sub_test$Monthly_Debt)
rmse
R2 <- R2(predictions, sub_test$Monthly_Debt)
R2
error_rate <- rmse/mean(sub_test$Monthly_Debt)
error_rate

```
39% of the variation in Monthly Debt can be modeled by this quadratic relationship. This is better than the 30% in the Linear relationship. Error rate is 40%, the same as the linear relationship.

## b) Splines
Smooth curve is fitted to the data with segments of polynomial terms called Knots.

```{r warning=FALSE, message=FALSE}

library(splines)
set.seed(9650)

knots <- quantile(sub_train$Monthly_Debt, p=c(0.25, 0.5, 0.75))

splinemodel <- lm(Monthly_Debt ~ bs(Annual_Income, knots=knots), data=sub_train)
summary(splinemodel)

#Prediction  
predictions <-  splinemodel %>% predict(sub_test)

# Performance
RMSE <- RMSE(predictions, sub_test$Monthly_Debt)
RMSE
R2 <- R2(predictions, sub_test$Monthly_Debt)
R2
error_rate <- RMSE/mean(sub_test$Monthly_Debt)
error_rate

# Visualization
ggplot(sub_train, aes(Annual_Income, Monthly_Debt)) +
  geom_point() +
  stat_smooth(method=lm, formula = y~splines::bs(x, df=3))

```
The results from Spline, adjusted R2 is 30%. Error rate is 40%. Both are the same as the linear relationship.

## c) Generalized Linear Model
Fits spline models with a selection of automate knots.

```{r warning=FALSE, message=FALSE}

library(mgcv)

gmmodel <- gam(Monthly_Debt ~ s(Annual_Income), data=sub_train)

# Predictions
gam_predictions <- gmmodel %>% predict(sub_test)

# Performance
RMSE <- RMSE(gam_predictions, sub_test$Monthly_Debt)
RMSE
R2 <- R2(gam_predictions, sub_test$Monthly_Debt)
R2
error_rate <- RMSE/mean(sub_test$Monthly_Debt)
error_rate
```
gam model gives the same result as Spline.

## d) Multcollinearity
Variance inflation factor (VIF) quantifies the extend of correlation between one predictor variable and the other predictor variable. VIF below 1 is not correlated, 1-5 moderate, above 5 correlated.

```{r warning=FALSE, message=FALSE }

# Not include factor variables
train_nofactors <- sub_train[c(2,4,5,6,9,10,11,12,14,15)]

model_all <- lm(Monthly_Debt ~., data=train_nofactors)

car:: vif(model_all)
```
Variance inflation factor (VIF) shows Monthly Debt is moderately correlated with Current Credit Balance and Maximum Open Credit. This aligns with the correlation map we observed earlier. 

# STEP 8: MODEL SELECTION, RIDGE AND LASSO REGRESSION
## a) Model Selection
```{r warning=FALSE, message=FALSE}
library(leaps)

checkmodels <- regsubsets(Annual_Income ~., data=sub_train, nvmax=13)
summary(checkmodels)

# Find best model for R2, CP, and BIC, respectively
res_sum <- summary(checkmodels)
data.frame(Adj.R2=which.max(res_sum$adjr2), CP=which.min(res_sum$cp), BIC=which.min(res_sum$bic)) #, AIC=which.min(res_sum$AIC))

# Best AIC model
library(MASS)

full_model <- lm(Annual_Income ~., data=sub_train)

step_model <- stepAIC(full_model, direction='both', trace=FALSE)
summary(step_model)

```
Since Annual Income is the #1 most important feature in determining Loan Status, I decided to predict Annual Income base on all other variable. In terms of adjusted R2, Model #14 is the best. Model 14 accounts for Months_since_last_delinquent, Number_of_Open_Accounts, Monthly_Debt Years_of_Credit_History, Purpose, Loan_Status and Current_Loan_Amount. In terms of CP, Model #9 gives the best result. In terms of BIC, Model #6 gives the best result.

## b) Ridge Regression
Ridge Regression shrinks contribution from features of less prominent . Lasso Regression set zero for features of less prominent.

```{r warning=FALSE, message=FALSE}

library(glmnet)
set.seed(9650)

# Remove column 5 (Annual_Income)
x <- model.matrix(Annual_Income~., sub_train)[, -5]
y <- sub_train$Annual_Income

# alpha=0 for Ridge regression
cv <- cv.glmnet(x, y, alpha=0)
cv$lambda.min # Fit the final model with this paramter

model <- glmnet(x, y, alpha=0, lamba = cv $ lambda.min)
#coef(model)

# Predictions
x_test <- model.matrix(Annual_Income~., sub_test)[, -5]

predictions <- model %>% predict(x_test)  %>% as.vector

# Model Performance evaluation
RMSE <- RMSE(predictions, sub_test$Annual_Income)
RMSE

```


# STEP 9: LOGISTIC REGRESSION

## a) Loan Status as a Function of Monthly Debt
```{r warning=FALSE, message=FALSE}
set.seed(9650)

logreg_debt <- glm(Loan_Status ~ Monthly_Debt, data=sub_train, family=binomial)
# Show coefficient
summary(logreg_debt)$coef
```
The p-value for Loan Status and Monthly Debt relationship is 0.52. Meaning this relationship is not significant. So I will examing a different feature.

## b) IMPROVEMENT
### Loan Status as a Function of Income
```{r warning=FALSE, message=FALSE}

logreg_income <- glm(Loan_Status ~ Annual_Income, data=sub_train, family=binomial)
# Show coefficient
summary(logreg_income)$coef

# Predictions
logreg_probs <- logreg_income %>% predict(sub_test, type='response')

# Convert probability to integers
logreg_predictions <- ifelse(logreg_probs > 0.5, 'Fully Paid', 'Charged Off')
logreg_predictions <- as.factor(logreg_predictions)
typeof(logreg_predictions)
typeof(sub_test$Loan_Status)

# Performance confusion matrix to see accuracy and other parameter values
confusionMatrix(logreg_predictions, sub_test$Loan_Status)

# compute accuracy by comparing prediction with actual classification
mean(logreg_predictions == sub_test$Loan_Status)

```
The p-value for Loan Status and Annual Income using logistic regression relationship is 5.5e-8. Meaning this relationship is significant. Accuracy is only 55%. The above model only use a subset of the data. I'll see if including all the data would improve performance.


## c) IMPROVEMENT
### Using All of the Data
```{r warning=FALSE, message=FALSE}
# Set up train and test set
indexTrain <- createDataPartition(y=bankloan$Loan_Status, p=0.75, list=FALSE) 
training <- bankloan[indexTrain, ]
testing <- bankloan[-indexTrain, ]

# Downsampling to balance data
sub_train <- downSample(x=training[, -ncol(training)], y=training$Loan_Status)
sub_test <- downSample(x=testing[, -ncol(testing)], y=testing$Loan_Status)

table(sub_train$Loan_Status)
table(sub_test$Loan_Status)

logreg_all <- glm(Loan_Status ~ Annual_Income, data=sub_train, family=binomial)
# Show coefficient
summary(logreg_all)$coef

# Predictions
logreg_probs <- logreg_all %>% predict(sub_test, type='response')

# Convert probability to integers
logreg_pred_all <- ifelse(logreg_probs > 0.5, 'Fully Paid', 'Charged Off')
logreg_pred_all <- as.factor(logreg_pred_all)
typeof(logreg_pred_all)
typeof(sub_test$Loan_Status)

# Performance confusion matrix to see accuracy and other parameter values
confusionMatrix(logreg_pred_all, sub_test$Loan_Status)

# compute accuracy by comparing prediction with actual classification
mean(logreg_pred_all == sub_test$Loan_Status)
```
Using all of the data, the accuracy is still only 55%. The p-value shows this logistic regression relationship is significant. This is most like because Annual Income alone is not enough to predict Loan Status. I'll try using all the features. 

## d) IMPROVEMENT
### Using All Features

```{r warning=FALSE, message=FALSE}

logreg_all.features <- glm(Loan_Status ~., data=sub_train, family=binomial)
# Show coefficient
summary(logreg_all.features)$coef

# Predictions
logreg_probs.features <- logreg_all.features %>% predict(sub_test, type='response')

# Convert probability to integers
logreg_pred_all.features <- ifelse(logreg_probs.features > 0.5, 'Fully Paid', 'Charged Off')
logreg_pred_all.features <- as.factor(logreg_pred_all.features)
typeof(logreg_pred_all.features)
typeof(sub_test$Loan_Status)

# Performance confusion matrix to see accuracy and other parameter values
confusionMatrix(logreg_pred_all.features, sub_test$Loan_Status)

# compute accuracy by comparing prediction with actual classification
mean(logreg_pred_all.features == sub_test$Loan_Status)
```
Wonderful! Using all features improved performance to 100% in accuracy, sensitivity, specificity and Kappa. 

# CONCLUSION AND DISCUSSION
All features of the bank loan dataset were examined closely. Quantitative variables were compared between the two classes. Correlation was analyzed. Simple Linear Regression was implemented to model relationship of one quantative variable with another variable or combination of variables. Nonliear regression was also implemented using polynomial, Spline and Generalized Linear Model. Ridge Regression and Logistic Regression were implemented. Improvements were made on Logistic Regression and the final accuracy of 100% was achieved. 

One weakness of this data is that there could be a large variation in the value, even after removing outliers and influential cases. There is a lot of variation when the numbers are high, such as at high Annual Income, high Monthly Debt, high Current Credit Balance, and high Maximum Open Credit. I supposed this could be due to different people manage money differently even among people with the same income. 

In the future, I would like to implement PCA algorithms to treat multicollinearity properly. Also, I'd like to learn other algorithms like Neural Network and Deep Learning, and Naive Baye's since my data have categorical variables. 
